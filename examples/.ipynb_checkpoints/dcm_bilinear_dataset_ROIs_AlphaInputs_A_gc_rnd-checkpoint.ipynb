{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bilinear DCM for HGA in MEG signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import jax, jax.random as jr, jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "from functools import partial\n",
    "\n",
    "import vbjax as vb\n",
    "import tqdm\n",
    "\n",
    "import numpyro, time\n",
    "numpyro.set_host_device_count(jax.local_device_count())\n",
    "import numpyro.infer, numpyro.distributions as dist\n",
    "from numpyro.infer import Predictive\n",
    "\n",
    "import frites\n",
    "from frites.conn import (conn_covgc, conn_reshape_directed, conn_reshape_undirected)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the experimental data to be modelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../..'\n",
    "data_path = base_dir+'/data/meg_visuomotor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarsAtlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "atlas_path = data_path + '/sc/MarsAtlas_BV_2015.xls'\n",
    "atlas = pd.read_excel(atlas_path)\n",
    " # Cortical ROIs\n",
    "name_ROIs = atlas['Hemisphere'][0:82] + '_' + atlas['Name'][0:82]\n",
    "atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random subject\n",
    "# subject = random.sample(range(1,9),1)\n",
    "subject = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action- or Stimulus-aligned ROIs signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.utils.reads import *\n",
    "meg_data_path = data_path+'/hga/meg_data_stimulus.mat'\n",
    "time_pts, subject_data = read_subject_data(data_path=meg_data_path, subject=subject, onset_time=False)\n",
    "subject_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninputs=2  # Initial number of inputs of same kind, but more extra inputs can be added later\n",
    "ROIs_set = jnp.asarray([22, 15, 0, 63, 56, 41])\n",
    "# ROIs_set = [0, 15, 22]\n",
    "ntrl, nvar, ntime = 1, len(ROIs_set), subject_data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_mean = jnp.matrix_transpose(jnp.mean(subject_data[:,ROIs_set], axis=0))\n",
    "xs_exp = jnp.expand_dims(xs_mean, axis=0)\n",
    "xs_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"nvar\" non-reapeating random ROIs\n",
    "# ROIs_set = random.sample(range(0,82), nvar)\n",
    "name_ROIs_set = name_ROIs[ROIs_set]\n",
    "\n",
    "fig = figure(figsize=(7,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_prop_cycle(color=['b', 'g', 'r', 'c', 'y', 'k'])\n",
    "ax.plot(xs_exp[0], label = name_ROIs_set); legend()\n",
    "xlabel('time (samples)')\n",
    "title(f'Subject {subject[0]} \\n Experimental data: MEG envelope Z-scores', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# To save the data back to disk\n",
    "data=dict()\n",
    "for i, name in enumerate(name_ROIs_set):\n",
    "    data[name]=xs_exp[0].T[i]\n",
    "    \n",
    "file = open('../../sample_data.json', 'wb')\n",
    "jax.numpy.save(file,data, allow_pickle=True)\n",
    "sample_data = numpy.load('../../sample_data.json', allow_pickle=True)\n",
    "sample_data.item().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots(1, 2, sharey=True, sharex=True)\n",
    "fig.set_figheight(6); fig.set_figwidth(18)\n",
    "\n",
    "subplot(121)\n",
    "axes[0].set_prop_cycle(color=['b', 'g', 'r'])\n",
    "axes[0].plot(xs_exp[0,...,:3], label = name_ROIs_set[:3]); legend(fontsize=18)\n",
    "xlabel('time (samples)', fontsize=18)\n",
    "title(f'Subject {subject[0]} \\n Left hemisphere: Z-scores', fontsize=20)\n",
    "\n",
    "subplot(122)\n",
    "axes[1].set_prop_cycle(color=['c', 'y', 'k'])\n",
    "axes[1].plot(xs_exp[0,...,3:], label = name_ROIs_set[3:]); legend(fontsize=18)\n",
    "xlabel('time (samples)', fontsize=18)\n",
    "title(f'Subject {subject[0]} \\n Right hemisphere: Z-scores', fontsize=20)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the observation noise from baseline activity in subject trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenates all baseline activity in trials for each single ROI\n",
    "onset_ind = numpy.where(time_pts==0.)[0][0]\n",
    "subject_obsnoise_ROIs = jax.vmap(lambda roi: jnp.array(subject_data)[:,roi,:onset_ind].ravel())(ROIs_set).T\n",
    "subject_obsnoise_ROIs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs = range(0,nvar)\n",
    "color=['b', 'g', 'r', 'c', 'y', 'k']\n",
    "\n",
    "nrows, ncols = int(nvar/2),2\n",
    "fig, axes = subplots(nrows, ncols, sharey=True, sharex=True)\n",
    "fig.set_figheight(3*nrows); fig.set_figwidth(15)\n",
    "\n",
    "ntrls = subject_data.shape[0]\n",
    "time_dts_ = jnp.r_[:ntrls*onset_ind]\n",
    "for row in ROIs[:nrows]:\n",
    "    # Plot prediction (left hemisphere)\n",
    "    axes[row, 0].plot(time_dts_, subject_obsnoise_ROIs[:,row], color[row])\n",
    "    axes[row, 0].text(.1,3., name_ROIs_set.iat[row]+': Obs. noise' , fontsize=15)\n",
    "    \n",
    "    # Plot prediction (right hemisphere)\n",
    "    axes[row, 1].plot(time_dts_, subject_obsnoise_ROIs[:,row+3], color[row+3])\n",
    "    axes[row, 1].text(.1,3., name_ROIs_set.iat[row+3]+': Obs. noise' , fontsize=15)\n",
    "    if row==nrows-1:\n",
    "        axes[row,0].set_xlabel('time (samples)')            \n",
    "        axes[row,1].set_xlabel('time (samples)')\n",
    "\n",
    "suptitle('Observation noise, computed from trials baseline period', fontsize=22)        \n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.utils.plots import *\n",
    "\n",
    "figure(figsize=(8,4))\n",
    "shrink, title_size = 1., 12\n",
    "\n",
    "obs_noise = subject_obsnoise_ROIs\n",
    "# Baseline observation noise\n",
    "cov_matrix = jnp.corrcoef(obs_noise.T)\n",
    "pre_matrix = jnp.linalg.inv(cov_matrix)\n",
    "subplot(121); plot_matrix(A=cov_matrix, title_str=f'Covariance matrix', title_size=title_size, \\\n",
    "                          shrink=shrink, vmin=0., ytickls=name_ROIs_set, xtickls=name_ROIs_set, no_diag=False, no_zeros=False)\n",
    "subplot(122); plot_matrix(A=pre_matrix, title_str=f'Precision matrix', title_size=title_size, \\\n",
    "                          shrink=shrink, xtickls=name_ROIs_set, no_diag=False, no_zeros=False)\n",
    "suptitle('Observation noise: from trials baseline periods', fontsize=15)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance-based Granger causality, as defined in Brovelli et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude baseline activity\n",
    "xs_exp = jnp.expand_dims(xs_mean[onset_ind:], axis=0)\n",
    "times= np.squeeze(time_pts[onset_ind:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_exp_asarray = np.asarray(jnp.matrix_transpose(xs_exp))\n",
    "gc_ = conn_covgc(data=xs_exp_asarray, t0=70, dt=210, step=5, lag=5, n_jobs=-1, times=times, roi = name_ROIs_set, method='gc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC=True\n",
    "# select directed connectivity at 0. and 0.4 seconds\n",
    "gc_0 = gc_.copy().sel(times=0.6, method='nearest')\n",
    "gc_0_2d = conn_reshape_directed(gc_0, to_dataframe=True).T\n",
    "\n",
    "# plot the 2d connectivity arrays\n",
    "kw = dict(cmap='viridis', square=True, annot=True, fmt=\".4f\", cbar=False)\n",
    "# figure(figsize=(5,5))\n",
    "sns.heatmap(gc_0_2d, **kw)\n",
    "title('Granger causality')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code the DCM in Jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ntrl  = Number of trials in one subject\n",
    "\n",
    "nvar  = Number of (cortical) brain signals recorded, e.g. sEEG channels \n",
    "\n",
    "ntime = Number of time points, with dt = 5ms (sampling period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_num = 100\n",
    "keys = jr.split(jr.PRNGKey(42), rnd_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Create coefficient matrices A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.utils.matrices import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix 'A' for DCM must contain source coefficients as rows, differently as in 'frites'.\n",
    "# This, because in vbjax DCM model's implementation, a column vector for sources is used instead of a row vector: A @ x\n",
    "# Source code: https://github.com/ins-amu/vbjax/blob/main/vbjax/neural_mass.py#L139C1-L139C57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = jnp.asarray(conn_reshape_directed(gc_0, to_dataframe=False).T).squeeze()\n",
    "i_rnd = random.sample(range(0,rnd_num),1)[0]\n",
    "A_rnd = jr.normal(keys[i_rnd], shape = gc.shape)\n",
    "\n",
    "diag_idx = jnp.diag_indices_from(gc)\n",
    "if GC: # A according to Granger causality \n",
    "\n",
    "    ### A is based on GC: A ~ GC\n",
    "    ## Deterministic version\n",
    "    A_gc = damped_dynamics(gc)\n",
    "    # Randomized version: A ~ Normal(0,gc)\n",
    "    gc_rnd = gc * A_rnd\n",
    "    A_gc_rnd = damped_dynamics(gc_rnd)\n",
    "\n",
    "    ### A is based on thresholded versions of GC: A ~ threshold(GC)\n",
    "    thrsh = 0.04\n",
    "    gc_vals = gc[jnp.where(~jnp.isnan(gc))]\n",
    "    thr_bool = (gc<thrsh*gc_vals.max())\n",
    "    gc_thr = gc.at[jnp.where(thr_bool)].set(0)\n",
    "    ## Non-binary deterministic version\n",
    "    A_gc_thr = damped_dynamics(gc_thr)\n",
    "\n",
    "    ## Non-binary randomized version: A ~ Normal(0,gc_thr)\n",
    "    gc_thr_rnd = gc_thr * A_rnd\n",
    "    A_gc_thr_rnd = damped_dynamics(gc_thr_rnd)\n",
    "\n",
    "    ## Binary deterministic version\n",
    "    gc_thr_bin = gc_thr.at[jnp.where(gc_thr>0)].set(1)\n",
    "    A_gc_thr_bin = damped_dynamics(gc_thr_bin)\n",
    "\n",
    "    # Binary randomized version: A ~ Normal(0,gc_thr_bin)\n",
    "    gc_thr_bin_rnd = gc_thr_bin * A_rnd\n",
    "    A_gc_thr_bin_rnd = damped_dynamics(gc_thr_bin_rnd)\n",
    "    \n",
    "else:  # A by random initialization\n",
    "    A_damp = damped_dynamics(A_rnd) # damped dynamics at each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_size=10\n",
    "\n",
    "thr_num=f'(thr={thrsh*gc_vals.max():.2f})'\n",
    "\n",
    "if GC:\n",
    "    figure(figsize=(12,9))\n",
    "    subplot(131); plot_matrix(A=gc, title_str='gc', title_size=title_size, ytickls=name_ROIs_set, vmin=0, vmax=1., xtickls=name_ROIs_set)\n",
    "    subplot(132); plot_matrix(A=gc_thr, title_str=f'gc_thr {thr_num}', title_size=title_size, vmin=0, vmax=1., xtickls=name_ROIs_set)\n",
    "    subplot(133); plot_matrix(A=gc_thr_bin, title_str='gc_thr_bin', title_size=title_size, vmin=0, vmax=1., xtickls=name_ROIs_set)\n",
    "\n",
    "else:\n",
    "    subplot(121); sns.heatmap(A=A_rnd, **kw, cbar_kws={\"shrink\": .35}); title('gc')\n",
    "    subplot(122); sns.heatmap(A=A_damp, **kw, cbar_kws={\"shrink\": .35})\n",
    "    title('A_rnd', fontsize=25)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_str = ''\n",
    "rnd_str = '_rnd'\n",
    "A_str = 'gc'+thr_str+rnd_str\n",
    "exec(f'gc_ref = gc{thr_str}')\n",
    "    \n",
    "A_init = jnp.zeros((rnd_num,nvar,nvar,))\n",
    "for i_rnd in arange(rnd_num):\n",
    "    A_rnd = jr.normal(keys[i_rnd], shape = gc.shape)\n",
    "    \n",
    "    if GC: # A according to Granger causality \n",
    "        # Randomized version: A ~ Normal(0,gc_ref)\n",
    "        gc_ref_rnd = gc_ref * A_rnd\n",
    "        A_gc_ref_rnd = damped_dynamics(gc_ref_rnd)\n",
    "        A_init = A_init.at[i_rnd].set(A_gc_ref_rnd)\n",
    "\n",
    "figure(figsize=(16,11))\n",
    "for i_rnd in arange(8):\n",
    "    subplot(3,4,i_rnd+1); plot_matrix(A_init[i_rnd], title_str=f'A = A_{A_str}[{i_rnd}]', title_size=title_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_rnd = random.sample(range(0,rnd_num),1)[0]\n",
    "exec(f'A = A_init[{i_rnd}]')\n",
    "A_diag = A[0,0]\n",
    "\n",
    "figure(figsize=(8,4))\n",
    "if 'thr' in thr_str:\n",
    "    thr_num_=thr_num\n",
    "else:\n",
    "    thr_num_=''\n",
    "\n",
    "shrink, title_size = .62, 12\n",
    "subplot(121); plot_matrix(A=gc_ref, title_str=f'gc{thr_str} {thr_num_}', shrink=shrink, title_size=title_size,\\\n",
    "                          xtickls=name_ROIs_set, ytickls=name_ROIs_set)\n",
    "subplot(122); plot_matrix(A=A, title_str=f'A = A_{A_str}[{i_rnd}]', shrink=shrink, title_size=title_size, xtickls=name_ROIs_set)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = jnp.zeros((nvar, nvar, ninputs))\n",
    "# u3 modulates connection from node 1 to node 2\n",
    "# B = B.at[1,0,2].set(1)\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_shape='Gamma'\n",
    "\n",
    "L_VCcm_max, R_VCcm_max = xs_exp[0,...,2].max(), xs_exp[0,...,5].max()\n",
    "stim_h_max = 90*abs(A_diag)*jnp.asarray([L_VCcm_max, R_VCcm_max])\n",
    "stim_h = stim_h_max*jr.lognormal(keys[3], 1/16, shape=(ninputs,))\n",
    "\n",
    "# Nodes receiving direct exogenous inputs\n",
    "roi_stim = jnp.asarray([2,5])\n",
    "C = jnp.zeros((nvar, ninputs))\n",
    "C = C.at[roi_stim[0],0].set(stim_h[0]) # u1 drives node 3\n",
    "C = C.at[roi_stim[1],1].set(stim_h[1]) # u2 drives node 6\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,3))\n",
    "\n",
    "subplot(131); plot_matrix(A=C*jnp.r_[1,0], title_str='Left Input: ON', title_size=12, ytickls=name_ROIs_set, \\\n",
    "                          xtickls=['Input L', 'Input R'], no_diag=False)\n",
    "subplot(132); plot_matrix(A=C*jnp.r_[0,1], title_str='Right Input: ON', title_size=12, xtickls=['Input L', 'Input R'], no_diag=False)\n",
    "subplot(133); plot_matrix(A=C*jnp.r_[1,1], title_str='Both Inputs: ON', title_size=12, shrink=0.95, \\\n",
    "                          xtickls=['Input L', 'Input R'], no_diag=False)\n",
    "suptitle('C', fontsize=15)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Build a stimulus signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.utils.stims import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a stimulus signal\n",
    "dur, dt = 0.750, time_pts[1]-time_pts[0] # seconds\n",
    "dur_dt = int(ceil(dur/dt)) # time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_VCcm_idx, R_VCcm_idx = xs_exp[0,...,2].argmax(), xs_exp[0,...,5].argmax()\n",
    "pos_max = jnp.asarray([[L_VCcm_idx],[R_VCcm_idx]])/2.0\n",
    "\n",
    "if stim_shape=='Gamma':\n",
    "    stim_sh = 1\n",
    "    # Parameters for Gamma-shape input functions, as in Chen et al.[2008]\n",
    "    theta_sigma = 2*pos_max**2*jr.lognormal(keys[5],1/16, shape=(ninputs,1))\n",
    "    while True: # alpha must be larger than 1\n",
    "        theta_mu = 2*pos_max*jr.lognormal(keys[4],1/16, shape=(ninputs,1))\n",
    "        if (theta_mu > jnp.sqrt(theta_sigma)).all:\n",
    "            break\n",
    "    \n",
    "    alpha = theta_mu**2/theta_sigma\n",
    "    beta = theta_mu/theta_sigma\n",
    "    stim = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, ntime=ntime, alpha=alpha, beta=beta)\n",
    "    \n",
    "else: # Alpha input\n",
    "    stim_sh = 0\n",
    "    stim_tau = pos_max*jr.lognormal(keys[12],1/16, shape=(ninputs,1))\n",
    "    stim = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, ntime=ntime, stim_tau=stim_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,2))\n",
    "plot(C[2,0]*stim[0, 0].T, 'r-.', label = 'Input L'); legend()\n",
    "plot(C[5,1]*stim[0, 1].T, 'k-.', label = 'Input R'); legend()\n",
    "title(f'Input shapes for u: \"{stim_shape}\" functions', fontsize=15)\n",
    "xlabel('time (dt)')\n",
    "xlim(0,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Convergence time constant, as in Chen et al. (2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ODEs, dt should be small enough than all time constants, e.g. tau >= ~10*dt\n",
    "tau = 1/16*jr.lognormal(keys[40],1/4) #in seconds\n",
    "tau, tau/dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some model simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series for noise\n",
    "# n_std = subject_obsnoise_ROIs.std()\n",
    "n_std = 0.00\n",
    "eps = n_std*jr.normal(jr.PRNGKey(42), shape=(ntrl, ntime-onset_ind, nvar))\n",
    "eps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental conditions\n",
    "conditions = (jnp.r_[1,0], # Condition 1: Activates u1\n",
    "              jnp.r_[0,1], # Condition 2: Activates u2\n",
    "              jnp.r_[1,1], # Condition 3: Activates all inputs\n",
    "             )\n",
    "nconds=len(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.utils.models import *\n",
    "\n",
    "ts = jnp.r_[onset_ind:ntime]\n",
    "x0 = jnp.zeros(nvar)\n",
    "\n",
    "titles = 'Left Input: ON, Right Input: ON, Both inputs: ON'.split(',')\n",
    "nrows, ncols = nvar, len(conditions)\n",
    "\n",
    "fig, axes = subplots(nrows, ncols, sharey=False, sharex=True)\n",
    "fig.set_figheight(3*nvar); fig.set_figwidth(15)\n",
    "\n",
    "sse = lambda x,y: jnp.sum(jnp.square(x-y))\n",
    "us = jnp.matrix_transpose(stim[...,ts])\n",
    "time_dts = jnp.r_[:ntime]\n",
    "TRLs = jnp.r_[:ntrl]\n",
    "for i, cond in enumerate(conditions):\n",
    "    C_cond = C*conditions[i]\n",
    "    p = vb.DCMTheta(A=A/tau, B=B/tau, C=C_cond/tau)\n",
    "    xs = dcm_bilinear_predict(TRLs, dt, x0, ts, us, p, eps).squeeze()\n",
    "    for roi in ROIs:\n",
    "        ax = axes[roi, i]   \n",
    "\n",
    "        # Plot prediction\n",
    "        ax.plot(ts, xs[:,roi], linestyle='-.', color=color[roi])\n",
    "        ax.plot(time_dts, xs_mean[:,roi], color=color[roi])\n",
    "        if roi==0:\n",
    "            ax.set_title(f'{titles[i]}: sse = {sse(xs, xs_exp):0.2e}', fontsize=18)\n",
    "        if roi==nvar-1:\n",
    "            ax.set_xlabel('time (dt)')\n",
    "        if i==0:\n",
    "            ax.text(.1,.5, name_ROIs_set.iat[roi], fontsize=15) \n",
    "            \n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing all Matrices coefficients, and input parameters with possitive bounds, by means of jaxopt.ScipyBoundedMinimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abi_dcm.grad_desc.cost_functs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "GD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_idx = [1]\n",
    "if GD:\n",
    "    from jaxopt import ScipyBoundedMinimize    \n",
    "    # Flattening and concatenate all the parameters into a unique vector, \n",
    "    # as required by jaxopt's syntaxis\n",
    "\n",
    "    # Form a vector of input parameters\n",
    "    if stim_shape=='Gamma':\n",
    "        stim_pars_vec = jnp.concatenate([alpha.flatten(), beta.flatten()])\n",
    "        stim_pars_shape = (alpha.shape[0]+beta.shape[0],1)\n",
    "    else:\n",
    "        stim_pars_vec = stim_tau.flatten()\n",
    "        stim_pars_shape = stim_tau.shape\n",
    "\n",
    "    stim_pars_gd_all = jnp.zeros((nconds,rnd_num,)+stim_pars_vec.shape)\n",
    "    stim_pars_gd = jnp.zeros((nconds,)+stim_pars_shape)\n",
    "    C_gd_ = jnp.zeros((nconds,)+C.shape)\n",
    "    A_gd_ = jnp.zeros((nconds,)+A.shape)\n",
    "    \n",
    "    A_triu_idx, A_tril_idx = nZero_coeff_idx(A)\n",
    "    size_triu, size_tril = A_triu_idx[0].size, A_tril_idx[0].size\n",
    "    pjit_loss_fun_all = jax.jit(partial(loss_fun_all, C_shape=C.shape, stim_sh=stim_sh, ntime=ntime, onset_ind=onset_ind))\n",
    "    Optimizer = ScipyBoundedMinimize(fun=pjit_loss_fun_all, maxiter=70000, method=\"L-BFGS-B\") #  method=\"Nelder-Mead\")\n",
    "    for i_cond in cond_idx:\n",
    "        \n",
    "        tic = time.time()\n",
    "        print(f'Fitting model configuration {i_cond+1}...')\n",
    "\n",
    "        # Form a flat vector on non-null coefficients in C\n",
    "        C_cond_nZero_idx = jnp.where(C*conditions[i_cond])\n",
    "        C_stim = C[C_cond_nZero_idx]\n",
    "\n",
    "        for i_rnd in arange(1):\n",
    "            # print(f' Initializing matrix A as A = A_{A_str}[{i_rnd}]:')\n",
    "            A = A_init[i_rnd]\n",
    "            # Form a vector on non-null coefficients in A\n",
    "            A_triu_vec, A_tril_vec = A[A_triu_idx], A[A_tril_idx]\n",
    "            A_diag_arr = jnp.asarray([A[0,0]])\n",
    "            # print(f'  Intitial A_diag value: {A[0,0]: .3f}')\n",
    "            \n",
    "            # Call Optimization algorithm\n",
    "            n_params = len(stim_pars_vec)\n",
    "            p_hat_vec = jnp.concatenate([A_triu_vec, A_tril_vec, A_diag_arr, C_stim, stim_pars_vec])\n",
    "            if stim_shape=='Gamma':\n",
    "                # alpha must be larger than 1\n",
    "                lower_bounds = jax.lax.dynamic_update_slice(-jnp.ones_like(p_hat_vec)*jnp.inf, jnp.array([1.95,1.95,.010,.010]), (-n_params,))\n",
    "                upper_bounds = jax.lax.dynamic_update_slice( jnp.ones_like(p_hat_vec)*jnp.inf, jnp.array([3.00,3.00,.025,.025]), (-n_params,))        \n",
    "            else:\n",
    "                lower_bounds = jax.lax.dynamic_update_slice(-jnp.ones_like(p_hat_vec)*jnp.inf, jnp.ones(n_params)*dur_dt/10, (-n_params,))\n",
    "                upper_bounds = jax.lax.dynamic_update_slice(jnp.ones_like(p_hat_vec)*jnp.inf, jnp.ones(n_params)*dur_dt, (-n_params,))        \n",
    "            bounds = (lower_bounds, upper_bounds)\n",
    "            Optimizer_sol = Optimizer.run(p_hat_vec, bounds, A_triu_idx, A_tril_idx, B, C_cond_nZero_idx, tau, \\\n",
    "                                          pos_max, TRLs, dt, x0, eps, xs_exp)\n",
    "            # Reconstruct matrix A from a flat vector of estimated coefficients\n",
    "            # Upper triangle of A\n",
    "            A_triu_vec = jax.lax.dynamic_slice(Optimizer_sol.params, (0,), (size_triu,))\n",
    "            A_gd_triu_idx = (jnp.tile(i_cond,(size_triu,)),) + A_triu_idx\n",
    "            A_gd_ = A_gd_.at[A_gd_triu_idx].set(A_triu_vec)\n",
    "            # Lower triangle of A\n",
    "            A_tril_vec = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu,), (size_tril,))\n",
    "            A_gd_tril_idx = (jnp.tile(i_cond,(size_tril,)),) + A_tril_idx\n",
    "            A_gd_ = A_gd_.at[A_gd_tril_idx].set(A_tril_vec)\n",
    "            # Diagonal of A\n",
    "            A_gd_diag = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu+size_tril,), (1,))\n",
    "            A_gd_diag_idx = (jnp.tile(i_cond,(nvar,)),) + diag_idx\n",
    "            A_gd_ = A_gd_.at[A_gd_diag_idx].set(A_gd_diag) # Damped dynamics at each node\n",
    "            # print(f'  Estimated A_diag value: {A_gd_diag[0]: .3f}')\n",
    "    \n",
    "            # Reconstruct matrix C from a flat vector of estimated coefficients\n",
    "            C_opt = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu+size_tril+1,),(len(C_stim),))\n",
    "            C_gd_nZero_idx = (jnp.tile(i_cond,(len(C_stim),)),) + C_cond_nZero_idx\n",
    "            C_gd_ = C_gd_.at[C_gd_nZero_idx].set(C_opt)\n",
    "    \n",
    "            # Reconstruct input's parameters from a flat vector of estimated values\n",
    "            stim_pars_opt = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu+size_tril+1+len(C_stim),),(len(stim_pars_vec),))\n",
    "            stim_pars_gd_all = stim_pars_gd_all.at[i_cond,i_rnd].set(stim_pars_opt)\n",
    "\n",
    "        stim_pars_resh = jnp.reshape(mean(stim_pars_gd_all[i_cond], axis=0), stim_pars_shape)\n",
    "        stim_pars_gd = stim_pars_gd.at[i_cond].set(stim_pars_resh)\n",
    "        \n",
    "        toc = time.time() - tic\n",
    "        print(f' Elapsed time: {toc: .2f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:   \n",
    "    fig, axes = subplots(nrows, ncols, sharey=False, sharex=True)\n",
    "    fig.set_figheight(20); fig.set_figwidth(15)\n",
    "\n",
    "    sse_conds_ = []\n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for i_cond in cond_idx: # range(nconds):\n",
    "\n",
    "        # Extracting Matrices's coefficients from tensor of estimated values\n",
    "        A_cond, C_cond = A_gd_[i_cond], C_gd_[i_cond]\n",
    "\n",
    "        # Extracting Input's parameters from tensor of estimated values\n",
    "        if stim_shape=='Gamma':\n",
    "            alpha_cond, beta_cond = stim_pars_gd[i_cond,:ninputs], stim_pars_gd[i_cond,ninputs:]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, alpha=alpha_cond, beta=beta_cond)\n",
    "        else:\n",
    "            stim_tau_cond = stim_pars_gd[i_cond]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, stim_tau=stim_tau_cond)\n",
    "        us_hat = jnp.matrix_transpose(stim[...,ts])\n",
    "\n",
    "        # Model prediction\n",
    "        phat = vb.DCMTheta(A=A_cond/tau, B=B/tau, C=C_cond/tau)\n",
    "        xs_hat_gd = dcm_bilinear_predict(TRLs, dt, x0, ts, us_hat, phat, eps).squeeze()\n",
    "        \n",
    "        sse_cond = sse(xs_hat_gd, xs_exp)\n",
    "        sse_conds_.append(sse_cond)\n",
    "        for roi in ROIs:\n",
    "            ax = axes[roi,i_cond]   \n",
    "    \n",
    "            # Plot prediction\n",
    "            ax.plot(ts, xs_hat_gd[:,roi], color=color[roi], linestyle='-.')\n",
    "            ax.plot(time_dts, xs_mean[:,roi], color=color[roi])\n",
    "            if roi==0:\n",
    "                ax.set_title(f'{titles[i_cond]}:\\n sse = {sse_cond:0.2e}', fontsize=18)\n",
    "            if roi==nvar-1:\n",
    "                ax.set_xlabel('time (dt)')\n",
    "            if i_cond==0:\n",
    "                ax.text(.1,.5, name_ROIs_set.iat[roi], fontsize=15)\n",
    "                \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix A: relation between experimental data and estimated effective connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "if GD:\n",
    "\n",
    "    vmin, vmax = -1, 1\n",
    "    title_size = 10\n",
    "    \n",
    "    fig = figure(figsize=(12,7))\n",
    "    subplot(1,4,1); plot_matrix(A=gc_ref, shrink = 0.75, title_str=f'gc{thr_str}', title_size=12, ytickls=name_ROIs_set, xtickls=name_ROIs_set)\n",
    "    \n",
    "    for i_cond in cond_idx:\n",
    "        A_gd_max_ = [jnp.abs(A_gd_[i_cond]).max() for i_cond in cond_idx]\n",
    "        \n",
    "        subplot(2,4,i_cond + 2); plot_matrix(A=A_gd_[i_cond]/A_gd_max_[i_cond], \\\n",
    "                                             title_str=f'{titles[i_cond]} \\n sse={sse_conds_[i_cond]:.2e} \\n\\n Ahat_gd/|max|, |max|={A_gd_max_[i_cond]:.2f}', \\\n",
    "                                             title_size=title_size, vmin=vmin, vmax=vmax, shrink = 0.75)\n",
    "        subplot(2,4,i_cond + 6); plot_matrix(A=jnp.abs(A_gd_[i_cond])/A_gd_max_[i_cond], \\\n",
    "                                             title_str='|Ahat_gd|/|max|', \\\n",
    "                                             title_size=title_size, vmin=vmin, vmax=vmax, shrink = 0.75)\n",
    "        \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:\n",
    "    figure(figsize=(17,8))\n",
    "\n",
    "    for i_cond in cond_idx: # range(nconds):\n",
    "        # Extracting Matrices's coefficients from tensor of estimated values\n",
    "        A_cond = A_gd_[i_cond]\n",
    "\n",
    "        # Plotting A vs experimental GC\n",
    "        subplot(2,3,i_cond+1)\n",
    "        y = jnp.concatenate([    gc[A_triu_idx],     gc[A_tril_idx]])\n",
    "        x = jnp.concatenate([A_cond[A_triu_idx], A_cond[A_tril_idx]])/A_gd_max_[i_cond]\n",
    "        plot(x,y,'o')\n",
    "        title(f'{titles[i_cond]} \\n sse={sse_conds_[i_cond]:.2e}', fontsize=14)\n",
    "        xlabel(f'Ahat_gd/|max|, |max|={A_gd_max_[i_cond]:.2f}', fontsize=10)\n",
    "        xlim(-1,1)\n",
    "        if i_cond==0:\n",
    "            ylabel('gc')\n",
    "\n",
    "       # Plotting |A| vs experimental GC\n",
    "        # Plotting |A| vs experimental GC\n",
    "        subplot(2,3,i_cond+4)\n",
    "        y = jnp.concatenate([   gc[A_triu_idx],    gc[A_tril_idx]])\n",
    "        x = jnp.concatenate([jnp.abs(A_cond[A_triu_idx]), jnp.abs(A_cond[A_tril_idx])])/A_gd_max_[i_cond]\n",
    "        plot(x,y,'o')\n",
    "        xlabel('|Ahat_gd|/|max|', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('gc')\n",
    "\n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:   \n",
    "    fig, axes = subplots(1, ncols, sharey=True, sharex=True)\n",
    "    fig.set_figheight(3); fig.set_figwidth(15)\n",
    "    # title(f'Input shapes for u: \"{stim_shape}\" functions', fontsize=15)\n",
    "\n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for i_cond in cond_idx:\n",
    "\n",
    "        # Extracting Matrices's coefficients from tensor of estimated values\n",
    "        C_cond = C_gd_[i_cond]\n",
    "\n",
    "        # Extracting Input's parameters from tensor of estimated values\n",
    "        if stim_shape=='Gamma':\n",
    "            alpha_cond, beta_cond = stim_pars_gd[i_cond,:ninputs], stim_pars_gd[i_cond,ninputs:]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, alpha=alpha_cond, beta=beta_cond)\n",
    "        else:\n",
    "            stim_tau_cond = stim_pars_gd[i_cond]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, stim_tau=stim_tau_cond)\n",
    "            \n",
    "        axes[i_cond].plot(C_cond[2,0]*stim[0, 0].T, 'r-.', label = 'Input L'); axes[i_cond].legend()\n",
    "        axes[i_cond].plot(C_cond[5,1]*stim[0, 1].T, 'k-.', label = 'Input R'); axes[i_cond].legend()\n",
    "        axes[i_cond].set_xlabel('time (dt)')\n",
    "        \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD and stim_shape=='Alpha':\n",
    "    \n",
    "    fig, axes = subplots(2, ncols, sharey=False, sharex=True)\n",
    "    fig.set_figheight(8); fig.set_figwidth(15)\n",
    "\n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for i_cond in cond_idx:\n",
    "\n",
    "        subplot(2,3,i_cond+1)\n",
    "        hist(stim_pars_gd_all[i_cond,:,0],50,density=True, color='r'); title(f'{titles[i_cond]}:\\n stim_tau_L', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "        \n",
    "        subplot(2,3,i_cond+4)\n",
    "        hist(stim_pars_gd_all[i_cond,:,1],50,density=True, color='k'); title('stim_tau_R', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "     \n",
    "    tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD and stim_shape=='Gamma':\n",
    "    fig, axes = subplots(4, ncols)\n",
    "    fig.set_figheight(10); fig.set_figwidth(15)\n",
    "\n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for i_cond in cond_idx:\n",
    "\n",
    "        subplot(4,3,i_cond+1)\n",
    "        hist(stim_pars_gd_all[i_cond,:,0],50,density=True, color='r'); title(f'{titles[i_cond]}:\\n alpha_L', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "        \n",
    "        subplot(4,3,i_cond+4)\n",
    "        hist(stim_pars_gd_all[i_cond,:,2],50,density=True, color='k'); title('beta_L', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "        \n",
    "        subplot(4,3,i_cond+7)\n",
    "        hist(stim_pars_gd_all[i_cond,:,1],50,density=True, color='r'); title('alpha_R', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "        \n",
    "        subplot(4,3,i_cond+10)\n",
    "        hist(stim_pars_gd_all[i_cond,:,3],50,density=True, color='k'); title('beta_R', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('Frequency of occurence')\n",
    "     \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further optimizing matrices A and C by means of jaxopt.LevenbergMarquardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:\n",
    "    from jaxopt import LevenbergMarquardt \n",
    "\n",
    "    A_gd = jnp.zeros((nconds,)+A.shape)\n",
    "    C_gd = jnp.zeros((nconds,)+C.shape)\n",
    "    stim_pars_cond = jnp.zeros((nconds,)+stim_pars_shape)\n",
    "    pjit_loss_fun_A_C = jax.jit(partial(loss_fun_A_C, C_shape=C.shape, stim_sh=stim_sh, ntime=ntime, onset_ind=onset_ind))\n",
    "    Optimizer = LevenbergMarquardt(residual_fun=pjit_loss_fun_A_C, maxiter=70000)\n",
    "    for i_cond in cond_idx:\n",
    "        \n",
    "        tic = time.time()\n",
    "        print(f'Fitting model configuration {i_cond+1}...')\n",
    "\n",
    "        if sse_conds_[i_cond]<1e3:\n",
    "            A_cond, C_cond = A_gd_[i_cond], C_gd_[i_cond]\n",
    "            stim_pars_cond = stim_pars_cond.at[i_cond].set(stim_pars_gd[i_cond])\n",
    "        else:\n",
    "            exec(f'A = A_{A_str}')\n",
    "            A_cond, C_cond = A, C\n",
    "            stim_pars_cond = stim_pars_cond.at[i_cond].set(jnp.reshape(stim_pars_vec, stim_pars_shape))\n",
    "            \n",
    "        # Form a flat vector on non-null coefficients in C\n",
    "        C_cond_nZero_idx = jnp.where(C_cond*conditions[i_cond])\n",
    "        C_stim = C_cond[C_cond_nZero_idx]\n",
    "\n",
    "        # Form a flat vector on non-null coefficients in A\n",
    "        A_triu_idx, A_tril_idx = nZero_coeff_idx(A_cond)\n",
    "        A_triu_vec, A_tril_vec = A_cond[A_triu_idx], A_cond[A_tril_idx]\n",
    "        size_triu, size_tril = len(A_triu_idx[0]), len(A_tril_idx[0])\n",
    "        A_diag_arr = jnp.asarray([A_cond[0,0]])\n",
    "        \n",
    "        p_hat_vec = jnp.concatenate([A_triu_vec, A_tril_vec, A_diag_arr, C_stim])\n",
    "\n",
    "        # Call Levenberg-Marquardt algorithm\n",
    "        # print(f'Intitial A_diag value: {A_cond[0,0]: .3f}')\n",
    "        Optimizer_sol = Optimizer.run(p_hat_vec, A_triu_idx, A_tril_idx, B, C_cond_nZero_idx, tau, \\\n",
    "                                      stim_pars_cond[i_cond], TRLs, dt, x0, eps, xs_exp)\n",
    "        # Reconstruct matrix A from a flat vector of estimated coefficients\n",
    "        A_triu_vec = jax.lax.dynamic_slice(Optimizer_sol.params, (0,), (size_triu,))\n",
    "        A_gd_triu_idx = (jnp.tile(i_cond,(size_triu,)),) + A_triu_idx\n",
    "        A_gd = A_gd.at[A_gd_triu_idx].set(A_triu_vec)  \n",
    "    \n",
    "        A_tril_vec = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu,), (size_tril,))\n",
    "        A_gd_tril_idx = (jnp.tile(i_cond,(size_tril,)),) + A_tril_idx\n",
    "        A_gd = A_gd.at[A_gd_tril_idx].set(A_tril_vec)\n",
    "\n",
    "        A_gd_diag = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu+size_tril,), (1,))\n",
    "        A_gd_diag_idx = (jnp.tile(i_cond,(nvar,)),) + diag_idx\n",
    "        A_gd = A_gd.at[A_gd_diag_idx].set(A_gd_diag) # Damped dynamics at each node\n",
    "        print(f'   Estimated A_diag value: {A_gd_diag[0]: .3f}')\n",
    "\n",
    "        # Reconstruct matrix C from a flat vector of estimated coefficients\n",
    "        C_opt = jax.lax.dynamic_slice(Optimizer_sol.params, (size_triu+size_tril+1,),(len(C_stim),))\n",
    "        C_gd_nZero_idx = (jnp.tile(i_cond,(len(C_stim),)),) + C_cond_nZero_idx\n",
    "        C_gd = C_gd.at[C_gd_nZero_idx].set(C_opt)\n",
    "\n",
    "        toc = time.time() - tic\n",
    "        print(f'   Elapsed time: {toc: .2f} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:   \n",
    "    fig, axes = subplots(nrows, ncols, sharey=True, sharex=True)\n",
    "    fig.set_figheight(20); fig.set_figwidth(15)\n",
    "\n",
    "    sse_conds = []\n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for i_cond in cond_idx: # range(nconds):\n",
    "        # Extracting Matrices's coefficients from tensor of estimated values\n",
    "        A_cond, C_cond = A_gd[i_cond], C_gd[i_cond]\n",
    "\n",
    "        # Extracting Input's parameters from tensor of estimated values\n",
    "        if stim_shape=='Gamma':\n",
    "            alpha_cond, beta_cond = stim_pars_cond[i_cond,:ninputs], stim_pars_cond[i_cond,ninputs:]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, alpha=alpha_cond, beta=beta_cond)\n",
    "        else:\n",
    "            stim_tau_cond = stim_pars_cond[i_cond]\n",
    "            stim = stim_signal(shape=stim_shape, ninputs=ninputs, ntime=ntime, stim_onset=onset_ind, stim_tau=stim_tau_cond)\n",
    "        us_hat = jnp.matrix_transpose(stim[...,ts])\n",
    "                \n",
    "        phat = vb.DCMTheta(A=A_cond/tau, B=B/tau, C=C_cond/tau)\n",
    "        xs_hat_gd = dcm_bilinear_predict(x0, ts, us_hat, phat, eps).squeeze()\n",
    "        \n",
    "        sse_cond = sse(xs_hat_gd, xs_exp)\n",
    "        sse_conds.append(sse_cond)\n",
    "        for roi in ROIs:\n",
    "            ax = axes[roi,i_cond]   \n",
    "    \n",
    "            # Plot prediction\n",
    "            ax.plot(ts, xs_hat_gd[:,roi], color=color[roi], linestyle='-.')\n",
    "            ax.plot(time_dts, xs_mean[:,roi], color=color[roi])\n",
    "            if roi==0:\n",
    "                ax.set_title(f'{titles[i_cond]}:\\n sse = {sse_cond:0.2e}', fontsize=18)\n",
    "            if roi==nvar-1:\n",
    "                ax.set_xlabel('time (dt)')\n",
    "            if i_cond==0:\n",
    "                ax.text(.1,.7, name_ROIs_set.iat[roi], fontsize=15)\n",
    "                \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix A: relation between experimental data and estimated effective connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "if GD:\n",
    "    vmin, vmax = -1, 1\n",
    "    title_size = 10\n",
    "    \n",
    "    fig = figure(figsize=(12,7))\n",
    "    subplot(1,4,1); plot_matrix(A=gc_ref, shrink = 0.75, title_str=f'gc{thr_str}', title_size=12, ytickls=name_ROIs_set, xtickls=name_ROIs_set)\n",
    "    \n",
    "    for i_cond in cond_idx:\n",
    "        A_gd_max = [jnp.abs(A_gd[i_cond]).max() for i_cond in cond_idx]\n",
    "        \n",
    "        subplot(2,4,i_cond + 2); plot_matrix(A=A_gd[i_cond]/A_gd_max[i_cond], \\\n",
    "                                             title_str=f'{titles[i_cond]} \\n sse={sse_conds[i_cond]:.2e} \\n\\n Ahat_gd/|max|, |max|={A_gd_max[i_cond]:.2f}', \\\n",
    "                                             title_size=title_size, vmin=vmin, vmax=vmax, shrink = 0.75)\n",
    "        subplot(2,4,i_cond + 6); plot_matrix(A=jnp.abs(A_gd[i_cond])/A_gd_max[i_cond], \\\n",
    "                                             title_str='|Ahat_gd|/|max|', \\\n",
    "                                             title_size=title_size, vmin=vmin, vmax=vmax, shrink = 0.75)\n",
    "        \n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:\n",
    "    figure(figsize=(17,8))\n",
    "\n",
    "    for i_cond in cond_idx: # range(nconds):\n",
    "        # Extracting Matrices's coefficients from tensor of estimated values\n",
    "        A_cond = A_gd[i_cond]\n",
    "\n",
    "        # Plotting A vs experimental GC\n",
    "        subplot(2,3,i_cond+1)\n",
    "        y = jnp.concatenate([    gc[A_triu_idx],     gc[A_tril_idx]])\n",
    "        x = jnp.concatenate([A_cond[A_triu_idx], A_cond[A_tril_idx]])/A_gd_max[i_cond]\n",
    "        plot(x,y,'o')\n",
    "        title(f'{titles[i_cond]} \\n sse={sse_conds[i_cond]:.2e}', fontsize=14)\n",
    "        xlabel(f'Ahat_gd/|max|, |max|={A_gd_max[i_cond]:.2f}', fontsize=10)\n",
    "        xlim(-1,1)\n",
    "        if i_cond==0:\n",
    "            ylabel('gc')\n",
    "\n",
    "       # Plotting |A| vs experimental GC\n",
    "        # Plotting |A| vs experimental GC\n",
    "        subplot(2,3,i_cond+4)\n",
    "        y = jnp.concatenate([   gc[A_triu_idx],    gc[A_tril_idx]])\n",
    "        x = jnp.concatenate([jnp.abs(A_cond[A_triu_idx]), jnp.abs(A_cond[A_tril_idx])])/A_gd_max[i_cond]\n",
    "        plot(x,y,'o')\n",
    "        xlabel('|Ahat_gd|/|max|', fontsize=10)\n",
    "        if i_cond==0:\n",
    "            ylabel('gc')\n",
    "\n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GD:\n",
    "    figure(figsize=(6,5))\n",
    "    \n",
    "    C_all = jnp.concatenate( [ jnp.asarray( [C_gd[i_cond] for i_cond in cond_idx]), \\\n",
    "                               jnp.expand_dims(C,axis=0) \n",
    "                             ]\n",
    "                           )\n",
    "    vmin, vmax = jnp.min(C_all), jnp.max(C_all)\n",
    "    \n",
    "    for i_cond in cond_idx:\n",
    "        if i_cond==0:\n",
    "            ytickls=name_ROIs_set\n",
    "        else:\n",
    "            ytickls=False\n",
    "\n",
    "        if i_cond==2:\n",
    "            cbar=True\n",
    "        else:\n",
    "            cbar=False\n",
    "        subplot(2,3,i_cond+1); plot_matrix(A=C*conditions[i_cond], title_str=titles[i_cond], title_size=12, \\\n",
    "                                           shrink=0.85, vmin=vmin, vmax=vmax, ytickls=ytickls, no_diag=False)\n",
    "        \n",
    "        subplot(2,3,i_cond+4); plot_matrix(A=C_gd[i_cond], title_str='', shrink=0.85, \\\n",
    "                                           vmin=vmin, vmax=vmax, ytickls=ytickls, xtickls=['Input L', 'Input R'], no_diag=False)\n",
    "    \n",
    "    suptitle('C (top), C_gd (bottom)', fontsize=15)\n",
    "    tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Model the likelihood of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Model likelihood for i_cond = 2\n",
    "Lambda_max = 60\n",
    "Lambda = Lambda_max\n",
    "if GD:\n",
    "    model = numpyro.sample('xs_hat_c', dist.MultivariateNormal(loc=xs_hat_gd, covariance_matrix=1/Lambda*cov_matrix), rng_key=keys[6])\n",
    "    \n",
    "    nrows, ncols = int(nvar/2),2\n",
    "    fig, axes = subplots(nrows, ncols, sharey=True, sharex=True)\n",
    "    fig.set_figheight(3*nrows); fig.set_figwidth(15)\n",
    "    \n",
    "    time_dts = jnp.r_[:ntime]\n",
    "    for row in ROIs[:nrows]:\n",
    "        # Plot prediction (left hemisphere)\n",
    "        axes[row,0].plot(time_dts, xs_mean[:,row], color[row])\n",
    "        axes[row,0].plot(ts, model[:,row], color[row])\n",
    "        axes[row,0].text(.1,1.2, name_ROIs_set.iat[row] + ' vs Model Likelihood' , fontsize=15)\n",
    "        \n",
    "        # Plot prediction (right hemisphere)axes[row,0].plot(time_dts_, xs_mean[:,row][:,row], color[row])\n",
    "        axes[row,1].plot(time_dts, xs_mean[:,row+3], color[row+3])\n",
    "        axes[row,1].plot(ts, model[:,row+3], color[row+3])\n",
    "        axes[row,1].text(.1,1.2, name_ROIs_set.iat[row+3] + ' vs Model Likelihood' , fontsize=15)\n",
    "        if row==nrows-1:\n",
    "            axes[row,0].set_xlabel('time (samples)')            \n",
    "            axes[row,1].set_xlabel('time (samples)')\n",
    "        \n",
    "suptitle('Experimental data vs. Model Likelihood', fontsize=22)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Full Generative Model: Priors + Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD, GC_std = False, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCM_bilinear(Ahat0, Ahat0_triu_idx, Ahat0_tril_idx, A_fract, Chat0, Chat0_nZero_idx, stim_pars_cond, i_cond, xs_exp):\n",
    "\n",
    "    #### Priors for matrix A ####\n",
    "    A_hat = jnp.zeros(Ahat0.shape)\n",
    "    if GD:\n",
    "        Ahat0_diag = Ahat0[0,0]\n",
    "    else:\n",
    "        Ahat0_diag = A[0,0]\n",
    "    ## Damped dynamics for matrix A_hat\n",
    "    A_hat = A_hat.at[diag_idx].set(Ahat0_diag)\n",
    "    # A_diag_std = A_fract*jnp.abs(Ahat0_diag)\n",
    "    # A_diag_hat = numpyro.sample('A_diag_hat', dist.Normal(Ahat0_diag, A_diag_std))\n",
    "    # A_hat = A_hat.at[diag_idx].set(A_diag_hat)\n",
    "  \n",
    "    ### Complete A_hat from a flat array on non-null coefficients in Ahat0\n",
    "    ## Upper triangle for A_hat\n",
    "    if Ahat0_triu_idx:\n",
    "        Ahat0_triu_vec = Ahat0[Ahat0_triu_idx]\n",
    "        Ahat0_triu_std = A_fract*jnp.abs(Ahat0_triu_vec)\n",
    "        if GC_std:\n",
    "            Ahat0_triu_hat = numpyro.sample('A_triu_hat', dist.Normal(0., Ahat0_triu_std))\n",
    "        else:\n",
    "            Ahat0_triu_hat = numpyro.sample('A_triu_hat', dist.Normal(Ahat0_triu_vec, Ahat0_triu_std))\n",
    "        A_hat = A_hat.at[Ahat0_triu_idx].set(Ahat0_triu_hat)\n",
    "    ## Lower triangle for A_hat\n",
    "    if Ahat0_tril_idx:\n",
    "        Ahat0_tril_vec = Ahat0[Ahat0_tril_idx]\n",
    "        Ahat0_tril_std = A_fract*jnp.abs(Ahat0_tril_vec)\n",
    "        if GC_std:\n",
    "            Ahat0_tril_hat = numpyro.sample('A_tril_hat', dist.Normal(0., Ahat0_tril_std))\n",
    "        else:\n",
    "            Ahat0_tril_hat = numpyro.sample('A_tril_hat', dist.Normal(Ahat0_tril_vec, Ahat0_tril_std))\n",
    "        A_hat = A_hat.at[Ahat0_tril_idx].set(Ahat0_tril_hat)\n",
    "    ## A_hat\n",
    "    A_hat = numpyro.deterministic(f'A_hat_{i_cond}', A_hat)\n",
    "    \n",
    "    #### Priors for matrix C ####\n",
    "    C_hat = jnp.zeros(Chat0.shape)\n",
    "    ### Complete C_hat from a flat array on non-null coefficients in Chat0\n",
    "    Chat0_vec = jnp.expand_dims(Chat0[Chat0_nZero_idx], axis=1)\n",
    "    Chat0_hat = numpyro.sample('C_hat', dist.LogNormal(jnp.log(Chat0_vec),1/16))\n",
    "    C_hat = C_hat.at[Chat0_nZero_idx].set(Chat0_hat.squeeze())\n",
    "    C_hat = numpyro.deterministic(f'C_hat_{i_cond}',C_hat)\n",
    "    \n",
    "    #### Priors for the stimuli ####\n",
    "    if stim_shape=='Gamma':\n",
    "        # Parameters for Gamma-shape input functions, approx. as in Chen et al.[2008]\n",
    "        alpha_cond, beta_cond = stim_pars_cond[:ninputs], stim_pars_cond[ninputs:]\n",
    "        theta_sigma = numpyro.sample(f'theta_sigma_{i_cond}', dist.LogNormal(jnp.log(alpha_cond/beta_cond**2),1/16))\n",
    "        while True: # alpha must be larger than 1\n",
    "            theta_mu = numpyro.sample(f'theta_mu_{i_cond}', dist.LogNormal(jnp.log(alpha_cond/beta_cond),1/16))\n",
    "            if (theta_mu > jnp.sqrt(theta_sigma)).all:\n",
    "                break\n",
    "                \n",
    "        alpha = numpyro.deterministic(f'alpha_{i_cond}', theta_mu**2/theta_sigma)\n",
    "        beta = numpyro.deterministic(f'beta_{i_cond}', theta_mu/theta_sigma)\n",
    "        stim = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, alpha=alpha, beta=beta)\n",
    "    else:\n",
    "        stim_tau_cond = stim_pars_cond\n",
    "        stim_tau_hat = numpyro.sample(f'stim_tau_{i_cond}', dist.LogNormal(jnp.log(stim_pars_cond),1/16))\n",
    "        stim = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, stim_tau=stim_tau_hat)\n",
    "        \n",
    "    stim_hat = numpyro.deterministic(f'stim_{i_cond}', stim[...,ts])\n",
    "    us_hat = jnp.matrix_transpose(stim_hat)\n",
    "    \n",
    "    ### Prior for tau ####\n",
    "    tau_hat = numpyro.sample(f'tau_{i_cond}', dist.LogNormal(jnp.log(tau),1/16)) # in seconds\n",
    "    \n",
    "    ### Bilinear model's output ####\n",
    "    p_hat = vb.DCMTheta(A=A_hat/tau_hat, B=B/tau_hat, C=C_hat/tau_hat)\n",
    "    xs_hat_c = dcm_bilinear_predict(x0, ts, us_hat, p_hat, eps)\n",
    "\n",
    "    #### Likelihood model ####\n",
    "    Lambda = numpyro.sample(f'Lambda_{i_cond}', dist.LogNormal(jnp.log(Lambda_max),1))\n",
    "    numpyro.sample(f'xs_hat_c_{i_cond}', dist.MultivariateNormal(loc=xs_hat_c, covariance_matrix=1/Lambda*cov_matrix), obs=xs_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cond = 0\n",
    "if GD:\n",
    "    Ahat0, A_fract = A_gd.at[i_cond].get(), 0.03\n",
    "    Chat0 = C_gd.at[i_cond].get()\n",
    "else:\n",
    "    Ahat0, Chat0 = gc_ref, C*conditions[i_cond]\n",
    "    if GC_std: # Approx. as in Chen et al. (2008)\n",
    "        A_fract = 1.\n",
    "    else:\n",
    "        A_fract = 0.75\n",
    "Ahat0_triu_idx, Ahat0_tril_idx = nZero_coeff_idx(Ahat0)\n",
    "Chat0_nZero_idx = jnp.where(Chat0)\n",
    "\n",
    "data = (Ahat0, Ahat0_triu_idx, Ahat0_tril_idx, A_fract, Chat0, Chat0_nZero_idx, \\\n",
    "        stim_pars_cond[i_cond], i_cond, xs_exp,)\n",
    "filegraph = f'../../../figs/DCM/model_building/DCM_Bilinear_dataset_inferA_ProbGraph.png'\n",
    "numpyro.render_model(DCM_bilinear, model_args=data, render_params=True, render_distributions=True) #, filename=filegraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Optimization method: Markov Chains Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import MCMC, NUTS, init_to_mean, init_to_median\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "num_chains = int(jax.local_device_count()/len(conditions))\n",
    "rng_key = jax.random.PRNGKey(1106)\n",
    "\n",
    "def fit_model_conf(i_cond):\n",
    "    print(f'Fitting model configuration {i_cond+1}...')\n",
    "            \n",
    "    if GD:\n",
    "        Ahat0, A_fract = A_gd.at[i_cond].get(), 0.03\n",
    "        Chat0 = C_gd.at[i_cond].get()\n",
    "    else:\n",
    "        Ahat0, Chat0 = gc_ref, C*conditions[i_cond]\n",
    "        if GC_std: # To use GC in std of the prior probability for matrix A, resembling the approach in Chen et al. (2008)\n",
    "            A_fract = 1.\n",
    "        else:      # To use GC as mean of the prior probability for matrix A\n",
    "            A_fract = 0.10\n",
    "    Ahat0_triu_idx, Ahat0_tril_idx = nZero_coeff_idx(Ahat0)\n",
    "    Chat0_nZero_idx = jnp.where(Chat0)\n",
    "\n",
    "    nuts_kernel = NUTS(DCM_bilinear, target_accept_prob=0.95, init_strategy=init_to_mean)\n",
    "    mcmc = MCMC(nuts_kernel, num_warmup=1000, num_samples=1000, num_chains=num_chains)\n",
    "    mcmc.run(rng_key, Ahat0, Ahat0_triu_idx, Ahat0_tril_idx, A_fract, \\\n",
    "             Chat0, Chat0_nZero_idx, stim_pars_cond[i_cond], i_cond, xs_exp)\n",
    "    \n",
    "    postSamples = mcmc.get_samples()\n",
    "    DCM_PredictiveObject = Predictive(model=DCM_bilinear, posterior_samples=postSamples)\n",
    "    postPredData = DCM_PredictiveObject(rng_key, Ahat0, Ahat0_triu_idx, Ahat0_tril_idx, A_fract, \\\n",
    "                                        Chat0, Chat0_nZero_idx, stim_pars_cond[i_cond], i_cond, xs_exp=None)\n",
    "\n",
    "    return postSamples, postPredData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cond_idx = [0,1,2]\n",
    "element_run = Parallel(n_jobs=-1)(delayed(fit_model_conf)(i_cond) for i_cond in cond_idx)\n",
    "\n",
    "for i_run,i_cond in enumerate(cond_idx):\n",
    "    exec(f'postSamples_{i_cond}, postPredData_{i_cond} = element_run[{i_run}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model outputs VS experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = nvar, len(conditions)\n",
    "fig, axes = subplots(nrows, ncols, sharey=True, sharex=True)\n",
    "fig.set_figheight(2*nrows); fig.set_figwidth(15)\n",
    "\n",
    "sse_conds_bayes = []\n",
    "color=['b', 'g', 'r', 'c', 'y', 'k']\n",
    "for i_cond in cond_idx:\n",
    "\n",
    "    # Inputs\n",
    "    '''\n",
    "    # Mean-parameter estimated inputs\n",
    "    if stim_shape=='Alpha':\n",
    "        exec(f'stim_tau_hat = postSamples_{i_cond}[\"stim_tau_{i_cond}\"].mean()')\n",
    "        stim_phat_mean = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, stim_tau=stim_tau_hat)\n",
    "    else:\n",
    "        exec(f'alpha_hat = postSamples_{i_cond}[\"alpha_{i_cond}\"].mean()')\n",
    "        exec(f'beta_hat = postSamples_{i_cond}[\"beta_{i_cond}\"].mean()')\n",
    "        stim_phat_mean = stim_signal(shape=stim_shape, ninputs=ninputs, stim_onset=onset_ind, alpha=alpha_hat, beta=beta_hat)\n",
    "    us_hat_mean = jnp.matrix_transpose(stim_phat_mean)\n",
    "    \n",
    "    # Model prediction with the mean phat, tau_hat and us_hat\n",
    "    exec(f'A_hat = postSamples_{i_cond}[\"A_hat_{i_cond}\"].mean(axis=0)')\n",
    "    exec(f'C_hat = postSamples_{i_cond}[\"C_hat_{i_cond}\"].mean(axis=0)')\n",
    "    exec(f'tau_hat = postSamples_{i_cond}[\"tau_{i_cond}\"].mean()')\n",
    "    phat = vb.DCMTheta(A=A_hat/tau_hat, B=B/tau_hat, C=C_hat/tau_hat)\n",
    "    xs_phat_mean = dcm_bilinear_predict(x0, ts, us_hat_mean, phat, eps).squeeze()\n",
    "    '''\n",
    "    \n",
    "    # Mean estimated model prediction\n",
    "    xs_name = f'xs_hat_c_{i_cond}'\n",
    "    exec(f'xs_hat_mean = jnp.mean(postPredData_{i_cond}[\"{xs_name}\"], axis=0).squeeze()')\n",
    "    # 90% confidence intervals\n",
    "    # exec(f'percentiles = jnp.percentile(postSamples_{i_cond}[\"{xs_name}\"], jnp.asarray([5.0, 95.0]), axis=0).squeeze()')\n",
    "    exec(f'percentiles = jnp.percentile(postPredData_{i_cond}[\"{xs_name}\"], jnp.asarray([5.0, 95.0]), axis=0).squeeze()')\n",
    "\n",
    "    sse_cond = sse(xs_hat_mean, xs_exp)\n",
    "    sse_conds_bayes.append(sse_cond)\n",
    "    \n",
    "    for roi in ROIs:\n",
    "        ax = axes[roi,i_cond]\n",
    "\n",
    "        # Plot model predictions VS experimental data\n",
    "        ax.plot(time_dts, xs_mean[:,roi], color=color[roi])\n",
    "        # ax.plot(time_dts, xs_phat_mean[:,roi], color=color[roi], linestyle=':')\n",
    "        ax.plot(ts, xs_hat_mean[:,roi], color=color[roi], linestyle='-.')\n",
    "        \n",
    "        # plot 90% confidence level of predictions\n",
    "        ax.fill_between(ts, percentiles[0,...,roi], percentiles[1,...,roi], color=\"lightblue\")\n",
    "        if roi==0:\n",
    "            ax.set_title(f'{titles[i_cond]}:\\n sse = {sse_cond:0.2e}', fontsize=18)\n",
    "        if roi==nvar-1:\n",
    "            ax.set_xlabel('time (dt)')\n",
    "        if i_cond==0:\n",
    "            ax.text(.1,0.7, name_ROIs_set.iat[roi], fontsize=15)\n",
    "            \n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferred average values of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postSamples_0.keys(), postPredData_0.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix A: relation between experimental data and estimated effective connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "vmin, vmax = -1, 1\n",
    "\n",
    "fig = figure(figsize=(12,7.5))\n",
    "subplot(1,4,1); plot_matrix(A=gc_ref, shrink = 0.75, title_str=f'gc{thr_str}', title_size=12)\n",
    "\n",
    "for i_cond in cond_idx:\n",
    "    exec(f'A_hat = postSamples_{i_cond}[\"A_hat_{i_cond}\"].mean(axis=0)')\n",
    "    A_hat_max = jnp.abs(A_hat).max()\n",
    "    subplot(2,4,i_cond + 2); plot_matrix(A=A_hat/A_hat_max, \\\n",
    "                                         title_str=f'{titles[i_cond]} \\n sse={sse_conds_bayes[i_cond]:.2e} \\n\\n Ahat_Bay/|max|, |max|={A_hat_max:.2f}', \\\n",
    "                                         title_size=12, shrink = 0.75, vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    subplot(2,4,i_cond + 6); plot_matrix(A=jnp.abs(A_hat)/A_hat_max, title_str='|Ahat_Bay|/|max|', title_size=12, shrink = 0.75)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(17,8))\n",
    "\n",
    "for i_cond in cond_idx: # range(nconds):\n",
    "        \n",
    "    exec(f'A_hat = postSamples_{i_cond}[\"A_hat_{i_cond}\"].mean(axis=0)')\n",
    "    A_hat_max = jnp.abs(A_hat).max()\n",
    "    \n",
    "    # Plotting A vs experimental GC\n",
    "    subplot(2,3,i_cond+1)\n",
    "    y = jnp.concatenate([   gc[A_triu_idx],    gc[A_tril_idx]])\n",
    "    x = jnp.concatenate([A_hat[A_triu_idx], A_hat[A_tril_idx]])/A_hat_max\n",
    "    plot(x,y,'o')\n",
    "    title(f'{titles[i_cond]} \\n sse={sse_conds_bayes[i_cond]:.2e}', fontsize=14)\n",
    "    xlabel(f'Ahat_Bay/|max|, |max|={A_hat_max:.2f}', fontsize=10)\n",
    "    xlim(-1,1)\n",
    "    if i_cond==0:\n",
    "        ylabel('gc')\n",
    "\n",
    "    # Plotting |A| vs experimental GC\n",
    "    subplot(2,3,i_cond+4)\n",
    "    y = jnp.concatenate([   gc[A_triu_idx],    gc[A_tril_idx]])\n",
    "    x = jnp.concatenate([jnp.abs(A_hat[A_triu_idx]), jnp.abs(A_hat[A_tril_idx])])/A_hat_max\n",
    "    plot(x,y,'o')\n",
    "    xlabel(f'|Ahat_Bay|/|max|', fontsize=10)\n",
    "    if i_cond==0:\n",
    "        ylabel('gc')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(5,5))\n",
    "\n",
    "for i_cond in cond_idx:\n",
    "    if GD:\n",
    "        Chat0 = C_gd.at[i_cond].get()\n",
    "    else:\n",
    "        Chat0 = C*conditions[i_cond]\n",
    "    \n",
    "    exec(f'C_hat = postSamples_{i_cond}[\"C_hat_{i_cond}\"].mean(axis=0)')\n",
    "    subplot(2,3,i_cond+1); plot_matrix(A=Chat0, title_str=titles[i_cond], title_size=12, shrink=0.85, no_diag=False)\n",
    "    subplot(2,3,i_cond+4); plot_matrix(A=C_hat, title_str=titles[i_cond], title_size=12, shrink=0.85, no_diag=False)\n",
    "\n",
    "suptitle('C_prior (top), C_hat (bottom)', fontsize=15)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective stimuli: C_hat*stim_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting estimated vs original inputs\n",
    "inputs = range(0,ninputs)\n",
    "nrows, ncols = ninputs, len(conditions)\n",
    "fig, axes = subplots(nrows, ncols, sharey=True, sharex=True)\n",
    "fig.set_figheight(3*nrows); fig.set_figwidth(20)\n",
    "\n",
    "for i_cond in cond_idx:\n",
    "    \n",
    "    if GD:\n",
    "        Chat0 = C_gd.at[i_cond].get()\n",
    "    else:\n",
    "        Chat0 = C*conditions[i_cond]\n",
    "        \n",
    "    exec(f'C_hat = postSamples_{i_cond}[\"C_hat_{i_cond}\"].mean(axis=0)')\n",
    "\n",
    "    # Mean estimated inputs\n",
    "    exec(f'stim_hat_mean = jnp.mean(postPredData_{i_cond}[\"stim_{i_cond}\"], axis=0).squeeze().T')\n",
    "    # 90% confidence intervals\n",
    "    exec(f'stim_percentiles = jnp.percentile(postPredData_{i_cond}[\"stim_{i_cond}\"], jnp.asarray([5.0, 95.0]), axis=0).squeeze()')\n",
    "        \n",
    "    for i_inp in inputs:\n",
    "        ax = axes[i_inp,i_cond]\n",
    "        # Plot mean prediction\n",
    "        if i_inp==0:\n",
    "            node_stim, color = 2, 'r'\n",
    "        else:\n",
    "            node_stim, color = 5, 'k'\n",
    "            \n",
    "        # ax.plot(time_dts, jnp.c_[C_hat[node_stim,i_inp]*stim_hat_mean[:,i_inp].T, C_hat[node_stim,i_inp]*stim_phat_mean[:,i_inp].T])\n",
    "        ax.plot(ts, jnp.c_[C_hat[node_stim,i_inp]*stim_hat_mean[:,i_inp].T, Chat0[node_stim,i_inp]*stim[:,i_inp,onset_ind:].T], color=color, linestyle='-.')\n",
    "        # plot 90% confidence level of predictions\n",
    "        ax.fill_between(ts, C_hat[node_stim,i_inp]*stim_percentiles[0,i_inp], C_hat[node_stim,i_inp]*stim_percentiles[1,i_inp], color=\"lightblue\")\n",
    "        if i_inp==0:\n",
    "            ax.set_title(titles[i_cond], fontsize=18)\n",
    "        '''\n",
    "        if i_cond==0:\n",
    "            if i_inp==0:\n",
    "                ax.text(.1,.7,'Left', fontsize=15)\n",
    "            else:\n",
    "                ax.text(.1,.7, 'Right', fontsize=15)\n",
    "        '''\n",
    "        if i_inp==ninputs-1:\n",
    "            ax.set_xlabel('time (dt)',fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing priors and posterior probabilities for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cond=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convergence time constant: tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior samples\n",
    "exec(f'tau_hat_all = postSamples_{i_cond}[\"tau_{i_cond}\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior samples\n",
    "tau_pr = numpyro.sample(f'tau_{i_cond}', dist.LogNormal(jnp.log(tau),1/16), sample_shape=(tau_hat_all.shape[0],), rng_key=rng_key) # in seconds\n",
    "tau_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prior vs Posterior distributions\n",
    "figure(figsize=(15,3))\n",
    "ft_s = 10\n",
    "\n",
    "subplot(131); hist(tau_pr,50, density=True, color='c'); title('tau_prior', fontsize=ft_s)\n",
    "subplot(132); hist(tau_hat_all,50, density=True, color='b'); title('tau_post', fontsize=ft_s)\n",
    "subplot(133); hist([tau_pr, tau_hat_all],100, density=True, color=['c','b']); title('tau_prior VS tau_post', fontsize=ft_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance scale of the observation noise: Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior samples\n",
    "exec(f'Lambda_hat_all = postSamples_{i_cond}[\"Lambda_{i_cond}\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior samples\n",
    "Lambda_pr = numpyro.sample(f'Lambda_{i_cond}', dist.LogNormal(jnp.log(Lambda_max),1), sample_shape=(Lambda_hat_all.shape[0],), rng_key=rng_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prior vs Posterior distributions\n",
    "figure(figsize=(15,3))\n",
    "subplot(131); hist(Lambda_pr,50, density=True, color='c'); title('Lambda_prior', fontsize=ft_s)\n",
    "subplot(132); hist(Lambda_hat_all,50, density=True, color='b'); title('Lambda_post', fontsize=ft_s)\n",
    "subplot(133); hist([Lambda_pr, Lambda_hat_all],50, density=True, color=['c','b']); title('Lambda_prior VS Lambda_post', fontsize=ft_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stimuli parameters: stim_tau (for Alpha-shaped inputs) or alpha & beta (for Gamma-shaped inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.infer, numpyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior samples\n",
    "if stim_shape=='Alpha':\n",
    "    exec(f'stim_tau_hat_all = postSamples_{i_cond}[\"stim_tau_{i_cond}\"].squeeze()')\n",
    "else:\n",
    "    exec(f'alpha_hat_all = postSamples_{i_cond}[\"alpha_{i_cond}\"].squeeze().T')\n",
    "    exec(f'beta_hat_all = postSamples_{i_cond}[\"beta_{i_cond}\"].squeeze().T')\n",
    "    exec(f'theta_mu_all  = postSamples_{i_cond}[\"theta_mu_{i_cond}\"].squeeze()')\n",
    "    exec(f'theta_sigma_all  = postSamples_{i_cond}[\"theta_sigma_{i_cond}\"].squeeze()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior samples\n",
    "if stim_shape=='Alpha':\n",
    "    stim_tau_cond = stim_pars_cond[i_cond]\n",
    "    stim_tau_pr = numpyro.sample(f'stim_tau_{i_cond}', dist.LogNormal(jnp.log(stim_tau_cond),1/16), \\\n",
    "                                               sample_shape=(stim_tau_hat_all.shape[0],), rng_key=rng_key).squeeze().T\n",
    "else:\n",
    "    # Parameters for Gamma-shape input functions, as in Chen et al.[2008]\n",
    "    alpha_cond, beta_cond = stim_pars_cond[i_cond,:ninputs], stim_pars_cond[i_cond,ninputs:]\n",
    "    theta_mu_prior = numpyro.sample(f'theta_mu_{i_cond}', dist.LogNormal(jnp.log(alpha_cond/beta_cond),1/16), \\\n",
    "                                                         sample_shape=(theta_mu_all.shape[0],), rng_key=rng_key).squeeze().T\n",
    "    theta_sigma_prior = numpyro.sample(f'theta_sigma_{i_cond}', dist.LogNormal(jnp.log(alpha_cond/beta_cond**2),1/16), \\\n",
    "                                                               sample_shape=(theta_sigma_all.shape[0],), rng_key=rng_key).squeeze().T\n",
    "\n",
    "    alpha_prior = numpyro.deterministic(f'alpha_{i_cond}', theta_mu_prior**2/theta_sigma_prior)\n",
    "    beta_prior = numpyro.deterministic(f'beta_{i_cond}', theta_mu_prior/theta_sigma_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prior vs Posterior distributions\n",
    "if stim_shape=='Alpha':\n",
    "    figure(figsize=(15,8))\n",
    "    subplot(231); hist(stim_tau_pr[0],50,density=True, color='c'); title('stim_tau_L_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(232); hist(stim_tau_hat_all[...,0],50,density=True, color='b'); title('stim_tau_L_post', fontsize=ft_s)\n",
    "    subplot(233); hist([stim_tau_pr[0], stim_tau_hat_all[...,0]],100, density=True, color=['c','b'])\n",
    "    title('stim_tau_L_prior VS stim_tau_L_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(234); hist(stim_tau_pr[1],50,density=True, color='c'); title('stim_tau_R_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(235); hist(stim_tau_hat_all[...,1],50,density=True, color='b'); title('stim_tau_R_post', fontsize=ft_s)\n",
    "    subplot(236); hist([stim_tau_pr[1], stim_tau_hat_all[...,1]],100, density=True, color=['c','b'])\n",
    "    title('stim_tau_R_prior VS stim_tau_R_post', fontsize=ft_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stim_shape=='Gamma':\n",
    "    figure(figsize=(15,10))\n",
    "    subplot(431); hist(theta_mu_prior[0],50,density=True, color='c'); title('theta_mu_L_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(432); hist(theta_mu_all[...,0],50,density=True, color='b'); title('theta_mu_L_post', fontsize=ft_s)\n",
    "    subplot(433); hist([theta_mu_prior[0], theta_mu_all[...,0]],100, density=True, color=['c','b'])\n",
    "    title('theta_mu_L_prior VS theta_mu_L_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(434); hist(theta_sigma_prior[0],50,density=True, color='c'); title('theta_sigma_L_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(435); hist(theta_sigma_all[...,0],50,density=True, color='b'); title('theta_sigma_L_post', fontsize=ft_s)\n",
    "    subplot(436); hist([theta_sigma_prior[0], theta_sigma_all[...,0]],100, density=True, color=['c','b'])\n",
    "    title('theta_sigma_L_prior VS theta_sigma_L_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(437); hist(alpha_prior[0],50,density=True, color='c'); title('alpha_L_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(438); hist(alpha_hat_all.T[...,0],50,density=True, color='b'); title('alpha_L_post', fontsize=ft_s)\n",
    "    subplot(439); hist([alpha_prior[0], alpha_hat_all.T[...,0]],100, density=True, color=['c','b'])\n",
    "    title('alpha_L_prior VS alpha_L_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(4,3,10); hist(beta_prior[0],50,density=True, color='c'); title('beta_L_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(4,3,11); hist(beta_hat_all.T[...,0],50,density=True, color='b'); title('beta_L_post', fontsize=ft_s)\n",
    "    subplot(4,3,12); hist([beta_prior[0], beta_hat_all.T[...,0]],100, density=True, color=['c','b'])\n",
    "    title('beta_L_prior VS beta_L_post', fontsize=ft_s)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stim_shape=='Gamma':\n",
    "    figure(figsize=(15,10))\n",
    "    subplot(431); hist(theta_mu_prior[1],50,density=True, color='c'); title('theta_mu_R_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(432); hist(theta_mu_all[...,1],50,density=True, color='b'); title('theta_mu_R_post', fontsize=ft_s)\n",
    "    subplot(433); hist([theta_mu_prior[1], theta_mu_all[...,1]],100, density=True, color=['c','b']);\n",
    "    title('theta_mu_R_prior VS theta_mu_R_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(434); hist(theta_sigma_prior[1],50,density=True, color='c'); title('theta_sigma_R_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(435); hist(theta_sigma_all[...,1],50,density=True, color='b'); title('theta_sigma_R_post', fontsize=ft_s)\n",
    "    subplot(436); hist([theta_sigma_prior[1], theta_sigma_all[...,1]],100, density=True, color=['c','b'])\n",
    "    title('theta_sigma_R_prior VS theta_sigma_R_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(437); hist(alpha_prior[1],50,density=True, color='c'); title('alpha_R_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(438); hist(alpha_hat_all.T[...,1],50,density=True, color='b'); title('alpha_R_post', fontsize=ft_s)\n",
    "    subplot(439); hist([alpha_prior[1], alpha_hat_all.T[...,1]],100, density=True, color=['c','b'])\n",
    "    title('alpha_R_prior VS alpha_R_post', fontsize=ft_s)\n",
    "\n",
    "    subplot(4,3,10); hist(beta_prior[1],50,density=True, color='c'); title('beta_R_prior', fontsize=ft_s); ylabel('Probability')\n",
    "    subplot(4,3,11); hist(beta_hat_all.T[...,1],50,density=True, color='b'); title('beta_R_post', fontsize=ft_s)\n",
    "    subplot(4,3,12); hist([beta_prior[1], beta_hat_all.T[...,1]],100, density=True, color=['c','b'])\n",
    "    title('beta_R_prior VS beta_R_post', fontsize=ft_s)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C_1 and C_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior samples\n",
    "exec(f'C_hat_all = postSamples_{i_cond}[\"C_hat_{i_cond}\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior samples\n",
    "if GD:\n",
    "    Chat0 = C_gd.at[i_cond].get()\n",
    "else:\n",
    "    Chat0 = C*conditions[i_cond]\n",
    "\n",
    "C_1_pr = numpyro.sample(f'C_L_hat', dist.LogNormal(jnp.log(Chat0[2,0]),1/16), sample_shape=(C_hat_all.shape[0],), rng_key=rng_key)\n",
    "C_2_pr = numpyro.sample(f'C_R_hat', dist.LogNormal(jnp.log(Chat0[5,1]),1/16), sample_shape=(C_hat_all.shape[0],), rng_key=rng_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prior vs Posterior distributions\n",
    "figure(figsize=(15,6))\n",
    "\n",
    "subplot(231); hist(C_1_pr,50,density=True, color='c'); title('C_L_prior', fontsize=ft_s); # ylabel('Probability')\n",
    "subplot(232); hist(C_hat_all[...,2,0],50,density=True, color='b'); title('C_L_post', fontsize=ft_s)\n",
    "subplot(233); hist([C_1_pr, C_hat_all[...,2,0]],100, density=True, color=['c','b']); title('C_L_prior VS C_L_post', fontsize=ft_s)\n",
    "\n",
    "subplot(234); hist(C_2_pr,50,density=True, color='c'); title('C_R_prior', fontsize=ft_s); # ylabel('Probability')\n",
    "subplot(235); hist(C_hat_all[...,5,1],50,density=True, color='b'); title('C_R_post', fontsize=ft_s)\n",
    "subplot(236); hist([C_2_pr, C_hat_all[...,5,1]],100, density=True, color=['c','b']); title('C_R_prior VS C_R_post', fontsize=ft_s)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior samples of non-null coefficients in A_hat\n",
    "exec(f'A_hat_all = postSamples_{i_cond}[\"A_hat_{i_cond}\"]')\n",
    "A_nZero_idx = jnp.concatenate([A_triu_idx[0], A_tril_idx[0]]), jnp.concatenate([A_triu_idx[1], A_tril_idx[1]])\n",
    "A_hat_nZero = A_hat_all[:, A_nZero_idx[0], A_nZero_idx[1]] # Non-null coefficients in A_hat_all\n",
    "\n",
    "n_nZero = len(A_nZero_idx[0]) # Number of non-null coeffcients in matrices A_hat_all\n",
    "Ahat_lbs = [ f'A_hat[{A_nZero_idx[0][idx]},{A_nZero_idx[1][idx]}]' for idx in range(0,n_nZero) ]\n",
    "data_all = pd.DataFrame(A_hat_nZero, columns = Ahat_lbs)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior samples\n",
    "if GD:\n",
    "    Ahat0, A_fract = A_gd.at[i_cond].get(), 0.03\n",
    "else:\n",
    "    Ahat0 = gc_ref\n",
    "    if GC_std: # To use GC in std of the prior probability for matrix A, resembling the approach in Chen et al. (2008)\n",
    "        A_fract = 1.\n",
    "    else:      # To use GC as mean of the prior probability for matrix A\n",
    "        A_fract = 0.6\n",
    "Ahat0_std = A_fract*jnp.abs(Ahat0)\n",
    "\n",
    "## Upper triangle for A_prior\n",
    "if A_triu_idx:\n",
    "    A_prior_triu_vec = Ahat0[A_triu_idx]\n",
    "    A_prior_triu_std = A_fract*jnp.abs(A_prior_triu_vec)\n",
    "    if GC_std:\n",
    "        A_prior_triu = numpyro.sample('A_prior_triu', dist.Normal(0., A_prior_triu_std), sample_shape=(A_hat_all.shape[0],), rng_key=rng_key)\n",
    "    else:\n",
    "        A_prior_triu = numpyro.sample('A_prior_triu', dist.Normal(A_prior_triu_vec, A_prior_triu_std), sample_shape=(A_hat_all.shape[0],), rng_key=rng_key)\n",
    "## Lower triangle for A_prior\n",
    "if A_tril_idx:\n",
    "    A_prior_tril_vec = Ahat0[A_tril_idx]\n",
    "    A_prior_tril_std = A_fract*jnp.abs(A_prior_tril_vec)\n",
    "    if GC_std:\n",
    "        A_prior_tril = numpyro.sample('A_prior_tril', dist.Normal(0., A_prior_tril_std), sample_shape=(A_hat_all.shape[0],), rng_key=rng_key)\n",
    "    else:\n",
    "        A_prior_tril = numpyro.sample('A_prior_tril', dist.Normal(A_prior_tril_vec, A_prior_tril_std), sample_shape=(A_hat_all.shape[0],), rng_key=rng_key)\n",
    "\n",
    "A_prior_nZero = jnp.concatenate([A_prior_triu, A_prior_tril], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prior vs Posterior distributions\n",
    "numparams = n_nZero # Shouldn't be larger than n_nZero\n",
    "idx_rnd = sort(random.sample(range(0,n_nZero), numparams))\n",
    "\n",
    "figure(figsize=(15,3*nrows))\n",
    "\n",
    "nrows, ncols = len(idx_rnd),3\n",
    "n_subplts=nrows*ncols\n",
    "\n",
    "for i_idx, idx in enumerate(idx_rnd):\n",
    "        \n",
    "    ax = subplot(nrows,ncols,1 + 3*i_idx)\n",
    "\n",
    "    str_idx = f'{A_nZero_idx[0][idx]},{A_nZero_idx[1][idx]}'\n",
    "    hist(A_prior_nZero[:,idx],50, density=True, color='c')\n",
    "    title(f'A_prior[{str_idx}]', fontsize=ft_s)\n",
    "\n",
    "    subplot(nrows,ncols,2 + 3*i_idx, sharex=ax) \n",
    "    hist(A_hat_nZero[:,idx],50, density=True, color='b')\n",
    "    title(f'A_post[{str_idx}]', fontsize=ft_s)\n",
    "\n",
    "    subplot(nrows,ncols,3 + 3*i_idx, sharex=ax)\n",
    "    hist([A_prior_nZero[:,idx], A_hat_nZero[:,idx]],100, density=True, color=['c', 'b'])\n",
    "    title(f'A_prior[{str_idx}] vs A_post[{str_idx}]', fontsize=ft_s)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(data_all.iloc[:,idx_rnd], height=3, aspect=1, kind=\"hist\", corner=True)\n",
    "g.map_lower(sns.kdeplot, levels=4, color=\".2\")\n",
    "# g.map_upper(sns.kdeplot, levels=4, color=\".2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gelman-Rubin diagnostics for A_hat\n",
    "rhat_A = numpyro.diagnostics.split_gelman_rubin(A_hat_nZero)\n",
    "z_A = jnp.abs((A_prior_nZero.mean(axis=0) - A_hat_nZero.mean(axis=0)) / A_hat_nZero.std(axis=0))\n",
    "s_A = 1 - A_hat_nZero.std(axis=0)/A_prior_nZero.std(axis=0)\n",
    "\n",
    "plot(s_A.reshape(-1), z_A.reshape(-1), 'kx');\n",
    "xlim([0, 1]); ylim([0, max(1,z_A.max())])\n",
    "xlabel('Posterior shrinkage');\n",
    "ylabel('Posterior z score');\n",
    "grid(1)\n",
    "f'max rhat {rhat_A.max():0.3f}'\n",
    "title('Gelman-Rubin diagnostics for A', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "julia-1.8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
